import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer
from sklearn.impute import SimpleImputer
from sklearn.ensemble import IsolationForest
from sklearn.linear_model import LogisticRegression
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.decomposition import PCA
from sklearn.metrics import confusion_matrix
from sklearn.utils._set_output import _SetOutputMixin
import dill
from sklearn.utils import estimator_html_repr
import streamlit.components.v1 as components

##########################################################
# C√≥digo

df = pd.read_feather('credit_scoring.ftr')
X, y = df.drop(["data_ref", "index", "mau"], axis = 1), df["mau"]
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

X_train = X_train.reset_index(drop=True)
y_train = y_train.reset_index(drop=True)

num_cols = ['qtd_filhos',	
          'idade', 
          'tempo_emprego', 
          'qt_pessoas_residencia', 
          'renda']

cat_cols = ['sexo',
        'posse_de_veiculo',
        'posse_de_imovel',
        'tipo_renda',
        'educacao',
        'estado_civil',
        'tipo_residencia']

num_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

cat_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

preprocessor = ColumnTransformer(transformers=[
    ('num', num_pipeline, num_cols),
    ('cat', cat_pipeline, cat_cols)
])


class OutlierRemover(BaseEstimator, TransformerMixin, _SetOutputMixin):
    def __init__(self, contamination=0.1, num_cols=None):
        self.contamination = contamination
        self.model = IsolationForest(contamination=self.contamination, random_state=42)
        self.num_cols = num_cols
    
    def fit(self, X, y=None):
        if self.num_cols is not None:
            X_num = X[self.num_cols].copy()
            X_num = X_num.fillna(X_num.median())
            self.model.fit(X_num)
        return self
    
    def transform(self, X):
        if self.num_cols is not None:
            X_num = X[self.num_cols].copy()
            X_num = X_num.fillna(X_num.median())
            outliers = self.model.predict(X_num)
            mask = outliers != -1
            X = X.loc[mask]
        return X

outliers = OutlierRemover(contamination=0.1)

def selecionar_variaveis(X):
    if not hasattr(X, "columns"):
        return X
    cols = [c for c in X.columns if X[c].dtype != "object" or c == "sexo"]
    return X[cols]

variaveis = FunctionTransformer(selecionar_variaveis, validate=False)

pca = PCA(n_components=5)
pipe = Pipeline(steps=[
    ('classificador', LogisticRegression())
])

pipeline = Pipeline(steps=[
    ('Preprocessamento', preprocessor),
    ('Sele√ß√£o de variaveis', variaveis),
    ('Remo√ß√£o de outliers', outliers),
    ('PCA', pca),
    ('Classifica√ß√£o', pipe)
])

pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_train)

# Calcular a matriz de confus√£o
cm = confusion_matrix(y_train, y_pred)

plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='pink', 
            xticklabels=['Negativo', 'Positivo'], 
            yticklabels=['Negativo', 'Positivo'])
plt.xlabel('Previs√£o')
plt.ylabel('Real')
plt.title('Matriz de Confus√£o')
plt.show()
with open('Final_Model_Pipeline_Project.pkl', 'wb') as f:
    dill.dump(pipeline, f)
with open('Final_Model_Pipeline_Project.pkl', 'rb') as f:
    pipeline_bytes = f.read()
##########################################################

st.title("üß© Estudo dos Dados por Pipeline")

st.header("Criar um pipeline utilizando o sklearn pipeline para o preprocessamento")

st.markdown('''
---

### Pr√© processamento - Substitui√ß√£o de nulos (NaNs)

A importa√ß√£o e divis√£odos dados a serem analisados foi realizada da mesma forma como a anterior.

Para desenvolvimento do pr√© processamento dos dados como pipeline utilizei as seguintes bibliotecas
''')

st.code('''
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
''', language = "python")

st.write('''E do c√≥digo:''')

st.code('''
num_cols = ['qtd_filhos',	
          'idade', 
          'tempo_emprego', 
          'qt_pessoas_residencia', 
          'renda']

cat_cols = ['sexo',
        'posse_de_veiculo',
        'posse_de_imovel',
        'tipo_renda',
        'educacao',
        'estado_civil',
        'tipo_residencia']

num_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

cat_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

''', language = "python")

st.write('''Combinando ambos os c√≥digos desenvolvidos:''')
st.code('''
preprocessor = ColumnTransformer(transformers=[
    ('num', num_pipeline, num_cols),
    ('cat', cat_pipeline, cat_cols)
])
''', language = "python")

st.markdown(''' 
---
## Remo√ß√£o de outliers
Aqui utilizei as seguintes bibliotecas''')
st.code('''
from sklearn.ensemble import IsolationForest
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.utils._set_output import _SetOutputMixin
''', language = "python")
st.code('''
class OutlierRemover(BaseEstimator, TransformerMixin, _SetOutputMixin):
    def __init__(self, contamination=0.1, num_cols=None):
        self.contamination = contamination
        self.model = IsolationForest(contamination=self.contamination, random_state=42)
        self.num_cols = num_cols
    
    def fit(self, X, y=None):
        if self.num_cols is not None:
            X_num = X[self.num_cols].copy()
            X_num = X_num.fillna(X_num.median())
            self.model.fit(X_num)
        return self
    
    def transform(self, X):
        if self.num_cols is not None:
            X_num = X[self.num_cols].copy()
            X_num = X_num.fillna(X_num.median())
            outliers = self.model.predict(X_num)
            mask = outliers != -1
            X = X.loc[mask]
        return X

outliers = OutlierRemover(contamination=0.1)
''', language = "python")
st.markdown(''' 
---
## Sele√ß√£o de vari√°veis
Para isso as bibliotecas e c√≥digo foram''')
st.code('''
from sklearn.preprocessing import FunctionTransformer
''', language = "python")

st.code('''
def selecionar_variaveis(X):
    if not hasattr(X, "columns"):
        return X
    cols = [c for c in X.columns if X[c].dtype != "object" or c == "sexo"]
    return X[cols]

variaveis = FunctionTransformer(selecionar_variaveis, validate=False)
''', language = "python")
st.markdown(''' 
---
## Redu√ß√£o de dimensionalidade (PCA)
Para a descomposi√ß√£o de PCA o c√≥digo desenvolvido foi ''')
st.code('''
from sklearn.decomposition import PCA
pca = PCA(n_components=5)
''', language = "python")
st.markdown(''' 
---
## Cria√ß√£o de dummies
Aplicar o get_dummies() ou onehotencoder() para transformar colunas cat√©goricas do dataframe em colunas de 0 e 1.

* sexo
* posse_de_veiculo
* posse_de_imovel
* tipo_renda
* educacao
* estado_civil
* tipo_residencia

Por √∫ltimo utilizei:''')
st.code('''
from sklearn.linear_model import LogisticRegression
''', language = "python")
st.code('''
pipe = Pipeline(steps=[
    ('classificador', LogisticRegression())
])
''', language = "python")
st.markdown(''' 
---
## Pipeline
Para essa parte utilizei as seguintes bibliotecas''')
st.code('''
from sklearn.pipeline import Pipeline
''', language = "python")
st.markdown('''E o c√≥digo desenvolvido para o pipeline √©:''') 
st.code('''
pipeline = Pipeline(steps=[
    ('Preprocessamento', preprocessor),
    ('Sele√ß√£o de variaveis', variaveis),
    ('Remo√ß√£o de outliers', outliers),
    ('PCA', pca),
    ('Classifica√ß√£o', pipe)
])
''', language = "python")
st.write('''Ent√£o assim fica o Pipeline desenvolvido''')
st.write(pipeline.named_steps)
st.markdown(''' 
---
## Treinamento do modelo de regress√£o logistica
Assim utilizando o fit, o resultado final, obtido com rodando o pipeline completo √©:''')

html = estimator_html_repr(pipeline)
components.html(html, height=600, scrolling=True)
st.pyplot(plt)

st.markdown(''' ## Download do Modelo de Pipeline Treinado''')

st.download_button(
    label="üì• Download",
    data = pipeline_bytes, 
    file_name = "Final Model Pipeline Project.plk",
    mime="application/octet-stream")
st.markdown('''---
## Compara√ß√£o
Para compara√ß√£o e an√°lise da importancia de cada parte do pipeline desenvolvido, nessa se√ß√£o o usu√°rio de escolher quais quer ou n√£o implementar:''')

incluir_out = st.checkbox("Remover outliers", value=True)
incluir_var = st.checkbox("Sele√ß√£o de Variaveis", value=True)
incluir_pca = st.checkbox("PCA", value=True)
incluir_class = st.checkbox("Classificar Dados", value=True)

steps = [('Preprocessamento', preprocessor)]

# Pipeline Dinamico
if incluir_var:
    steps.append(('variaveis', variaveis))
if incluir_out:
    steps.append(('outlier', outliers))
if incluir_pca:
    steps.append(('pca', pca))
if incluir_class:
    steps.append(('classificacao', pipe))

pipeline_custom = Pipeline(steps)

st.write("Esse √© o Pipeline customizado:",
    
pipeline_custom.named_steps)

st.write("Ap√≥s treinar o Pipeline customizado os resultados obtidos foram:")
pipeline_custom.fit(X_train, y_train)

html2 = estimator_html_repr(pipeline_custom)
components.html(html2, height=600, scrolling=True)

y_pred = pipeline_custom.predict(X_train)

cmc = confusion_matrix(y_train, y_pred)

fig, ax = plt.subplots(figsize=(6, 4))
sns.heatmap(cmc, annot=True, fmt='d', cmap='pink', 
            xticklabels=['Negativo', 'Positivo'], 
            yticklabels=['Negativo', 'Positivo'])
plt.xlabel('Previs√£o')
plt.ylabel('Real')
plt.title('Matriz de Confus√£o do Pipeline Personalizado')

st.pyplot(fig)

st.success("‚úÖ Pipeline personalizado treinado!")

st.markdown(''' ## Download do Modelo de Pipeline Personalizado Treinado''')
with open('Final_Model_Personalized_Pipeline_Project.pkl', 'wb') as f:
    dill.dump(pipeline_custom, f)
with open('Final_Model_Personalized_Pipeline_Project.pkl', 'rb') as f:
    pipelinepers_bytes = f.read()

st.download_button(
    label="üì• Download",
    data = pipelinepers_bytes, 
    file_name = "Final Model Pipeline Personalizado Project.plk",
    mime="application/octet-stream")