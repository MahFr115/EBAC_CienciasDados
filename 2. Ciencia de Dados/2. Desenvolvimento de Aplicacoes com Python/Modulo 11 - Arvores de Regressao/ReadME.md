# üå≤ M√≥dulo 11 ‚Äì √Årvores de Regress√£o

Neste m√≥dulo, exploramos a aplica√ß√£o de **√°rvores de decis√£o no contexto de problemas de regress√£o**, ou seja, quando o objetivo √© prever uma **vari√°vel cont√≠nua**. Assim como nas √°rvores de classifica√ß√£o, a estrutura do modelo baseia-se em quebras sucessivas dos dados, buscando minimizar o erro dentro de cada regi√£o resultante.

Esse m√≥dulo aprofunda o entendimento da estrutura, dos crit√©rios de divis√£o e das t√©cnicas de ajuste e poda para garantir que o modelo seja preciso e tenha boa capacidade de generaliza√ß√£o.

---

## üéØ Objetivos do M√≥dulo

‚úî Entender o que s√£o √°rvores de regress√£o e como diferem das √°rvores de classifica√ß√£o  
‚úî Compreender os conceitos de **vari√°vel explicativa (X)** e **vari√°vel resposta (y)**  
‚úî Aprender a identificar os melhores pontos de quebra para reduzir o erro  
‚úî Utilizar m√©tricas como **MSE, MAE e R¬≤** para avaliar o desempenho do modelo  
‚úî Ajustar uma √°rvore de regress√£o usando bibliotecas como Scikit-learn  
‚úî Aplicar t√©cnicas de **pr√©-poda e p√≥s-poda** para evitar overfitting  
‚úî Conhecer extens√µes do modelo como **Random Forests e Gradient Boosting**  

---

## üß© Principais Conceitos Abordados

| Conceito | Descri√ß√£o |
|----------|----------|
| **√Årvore de Regress√£o** | Modelo que prev√™ valores num√©ricos cont√≠nuos |
| **Impureza / Erro** | Medida utilizada para determinar a qualidade das divis√µes |
| **MSE (Erro Quadr√°tico M√©dio)** | Mede o erro elevando ao quadrado a diferen√ßa entre predi√ß√£o e valor real |
| **MAE (Erro Absoluto M√©dio)** | Mede o erro pela m√©dia dos valores absolutos das diferen√ßas |
| **R¬≤ (Coeficiente de Determina√ß√£o)** | Mede o quanto a varia√ß√£o da vari√°vel resposta √© explicada pelo modelo |
| **Quebra (Split)** | Ponto em que os dados s√£o divididos para reduzir o erro |
| **Profundidade M√°xima** | Limite de n√≠veis para controlar complexidade |
| **Pr√©-poda** | Impede que a √°rvore cres√ßa al√©m de um limite |
| **P√≥s-poda** | A √°rvore cresce por completo e depois √© simplificada |
| **Custo de Complexidade (Œ± / C_p)** | Par√¢metro para controlar a poda |
| **Ru√≠do** | Variabilidade aleat√≥ria que n√£o deve ser aprendida |
| **Variabilidade** | Grau de dispers√£o dos dados |
| **Random Forest / Gradient Boosting** | M√©todos baseados em m√∫ltiplas √°rvores para melhorar desempenho |

---

## üìë Gloss√°rio

Todos os termos t√©cnicos apresentados neste m√≥dulo est√£o organizados no arquivo **`Glossario.pdf`**, incluindo:  
*MSE, MAE, Impureza, Quebra, Profundidade M√°xima, R¬≤, Pr√©-poda, P√≥s-poda, Par√¢metro Alfa, Random Forests, Gradient Boosting, Base de Testes, Base de Treinamento,* entre outros.  
üìé *Local do arquivo: `./Glossario.pdf`* :contentReference[oaicite:0]{index=0}

---

## üõ† Ferramentas Utilizadas

| Ferramenta | Finalidade |
|-----------|------------|
| **Scikit-learn (sklearn)** | Constru√ß√£o, ajuste e poda da √°rvore |
| **Pandas / NumPy** | Prepara√ß√£o e manipula√ß√£o dos dados |
| **Jupyter Notebook** | Execu√ß√£o interativa e avalia√ß√£o do modelo |

---

## üìå Import√¢ncia do M√≥dulo

√Årvores de Regress√£o s√£o essenciais para entender como algoritmos supervisionados preditivos operam em vari√°veis cont√≠nuas. Al√©m disso, elas servem como base para t√©cnicas mais poderosas de Machine Learning, como **Random Forests e Gradient Boosting**, amplamente utilizadas no mercado para prever vendas, valores financeiros, consumo energ√©tico, entre outros cen√°rios.
